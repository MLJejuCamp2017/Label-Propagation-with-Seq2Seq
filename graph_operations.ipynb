{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "# similarity analysis using GPUs\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load all data (vectors)\n",
    "L = pickle.load(open('./data/graph/labeled.pickle', 'rb'))\n",
    "U = pickle.load(open('./data/graph/unlabeled.pickle', 'rb'))\n",
    "M = np.vstack([L,U]) # combining labeled data with unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "M = normalize(M) # L2 Norm before calculating cosine similarity\n",
    "\n",
    "last_index_l = L.shape[0]\n",
    "last_index_u = last_index_l + U.shape[0]\n",
    "\n",
    "# we only keep the closest neighbors\n",
    "max_neighs = 3\n",
    "size = M.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" FAISS operations \"\"\"\n",
    "res = faiss.StandardGpuResources()\n",
    "index = faiss.GpuIndexFlatIP(res, M.shape[1]) # build the index\n",
    "\n",
    "index.add(M) # add vectors to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [00:18<00:00, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "batch_num = int(np.ceil(size / batch_size))\n",
    "\n",
    "sims, inds = [], []\n",
    "\n",
    "for i in tqdm(range(batch_num)):\n",
    "    # actual search\n",
    "    similarities, indices = index.search(M[i*batch_size:int(np.min([(i+1)*batch_size, size]))],max_neighs+1)\n",
    "    \n",
    "    # remove self-references\n",
    "    batch_ids = np.vstack(np.arange(i*batch_size, int(np.min([(i+1)*batch_size, size]))))\n",
    "    xs, ys = np.where(indices==batch_ids)\n",
    "    similarities[xs,ys] = 0\n",
    "    \n",
    "    sims.extend(similarities)\n",
    "    inds.extend(indices)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = dict()\n",
    "edges_weights = dict()\n",
    "edges_ll = list()\n",
    "edges_lu = list()\n",
    "edges_uu = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275536/275536 [00:04<00:00, 62297.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(size)):\n",
    "    neighbors_indices = list(inds[i][sims[i].argsort()[-max_neighs::][::-1]])\n",
    "    correct_indices = [j for j in neighbors_indices if i < j]\n",
    "    graph.update({i:correct_indices})\n",
    "\n",
    "    n = len(correct_indices)\n",
    "\n",
    "    if n > 0:\n",
    "        edges = list(zip([i] * n, correct_indices))\n",
    "        take_indices = [np.where(inds[i]==x)[0][0] for x in correct_indices]\n",
    "        edges_weights.update(dict(zip(edges,np.take(sims[i],take_indices))))\n",
    "\n",
    "        for j in correct_indices:\n",
    "            if (0 <= i < last_index_l) and (0 <= j < last_index_l):\n",
    "                edges_ll.append((i,j))\n",
    "            elif (0 <= i < last_index_l) and (last_index_l <= j < last_index_u):\n",
    "                edges_lu.append((i,j))\n",
    "            else:\n",
    "                edges_uu.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181195 39347 173563 394105\n"
     ]
    }
   ],
   "source": [
    "print(len(edges_ll), len(edges_lu), len(edges_uu), len(edges_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save to file the data structure that we worked so hard to compute\n",
    "pickle.dump(dict(graph), open(\"./data/graph/graph.p\", \"wb\"))\n",
    "pickle.dump(dict(edges_weights), open(\"./data/graph/edges_weights.p\", \"wb\"))\n",
    "pickle.dump(list(edges_ll), open(\"./data/graph/edges_ll.p\", \"wb\"))\n",
    "pickle.dump(list(edges_lu), open(\"./data/graph/edges_lu.p\", \"wb\"))\n",
    "pickle.dump(list(edges_uu), open(\"./data/graph/edges_uu.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingsGraph:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.graph = nx.Graph()\n",
    "        #self.graph = pickle.load(open(\"./data/graph/graph.p\", \"rb\"))\n",
    "        edges_ll = pickle.load(open(\"./data/graph/edges_ll.p\", \"rb\"))\n",
    "        edges_lu = pickle.load(open(\"./data/graph/edges_lu.p\", \"rb\"))\n",
    "        edges_uu = pickle.load(open(\"./data/graph/edges_uu.p\", \"rb\"))\n",
    "        self.edges = edges_ll + edges_lu + edges_uu\n",
    "        self.edges_weights = pickle.load(open(\"./data/graph/edges_weights.p\", \"rb\"))\n",
    "\n",
    "        for (u,v) in self.edges:\n",
    "            self.graph.add_edge(u, v, weight=self.edges_weights.get((u, v)))\n",
    "\n",
    "    def weight(self,u,v):\n",
    "        if u < v:\n",
    "            return self.edges_weights.get((u,v))\n",
    "        else:\n",
    "            return self.edges_weights.get((v,u))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
