{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "UNK_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./nmt_data/vocab.en', 'r') as f, open('./nmt_data/vocab.vi', 'r') as g:\n",
    "    src_vocab = [x[:-1] for x in f.readlines()]\n",
    "    tgt_vocab = [x[:-1] for x in g.readlines()]\n",
    "    \n",
    "def list_to_dict(vocab_list):\n",
    "    ret = {}\n",
    "    for i in range(len(vocab_list)):\n",
    "        ret[i] = vocab_list[i]\n",
    "    \n",
    "    return ret\n",
    "\n",
    "src_vocab, tgt_vocab = list_to_dict(src_vocab), list_to_dict(tgt_vocab)\n",
    "src_vocab_inv, tgt_vocab_inv = {v: k for k, v in src_vocab.items()}, {v: k for k, v in tgt_vocab.items()}\n",
    "\n",
    "\n",
    "def word2idx(vocab_inv, word):\n",
    "    try:\n",
    "        ret = vocab_inv[word]\n",
    "    except:\n",
    "        ret = UNK_token\n",
    "    return ret\n",
    "\n",
    "def idx2word(vocab, idx):\n",
    "    return vocab[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "word2idx(src_vocab_inv, 'armpits'), idx2word(src_vocab, 17156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./nmt_data/train.en', 'r') as f:\n",
    "    ss_L = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "    \n",
    "with open('./nmt_data/mono.en', 'r') as f:\n",
    "    ss_U = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "    \n",
    "l = len(ss_L) #last index of labeled samples\n",
    "u = l + len(ss_U) #last index of all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "print(ss_L[0], [idx2word(src_vocab, x) for x in ss_L[0]])\n",
    "print(ss_U[0], [idx2word(src_vocab, x) for x in ss_U[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sources = ss_L\n",
    "sources.extend(ss_U)\n",
    "sources = np.array(sources)\n",
    "\n",
    "with open('./nmt_data/train.vi', 'r') as f:\n",
    "    targets = [[word2idx(tgt_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "\n",
    "targets = np.array(targets)\n",
    "\n",
    "def label(i):\n",
    "    if 0 <= i < l:\n",
    "        return targets[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "targets[0], [idx2word(tgt_vocab, x) for x in targets[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from embeddings_graph import EmbeddingsGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "max_time = 50\n",
    "time_major = True\n",
    "\n",
    "graph = EmbeddingsGraph().graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "source_sequence_lengths: src_seq_l,\n",
    "target_sequence_lengths:tgt_seq_l,\n",
    "    \n",
    "in_u1 = tf.placeholder(tf.int32, [None, max_time], name=\"in_u1\")\n",
    "in_v1 = tf.placeholder(tf.int32, [None, max_time], name=\"in_v1\")\n",
    "in_u2 = tf.placeholder(tf.int32, [None, max_time], name=\"in_u2\")\n",
    "in_v2 = tf.placeholder(tf.int32, [None, max_time], name=\"in_v2\")\n",
    "in_u3 = tf.placeholder(tf.int32, [None, max_time], name=\"in_u3\")\n",
    "in_v3 = tf.placeholder(tf.int32, [None, max_time], name=\"in_v3\")\n",
    "\n",
    "len_in_u1 = tf.placeholder(tf.int32, (), name=\"in_u1\")\n",
    "len_in_v1 = tf.placeholder(tf.int32, (), name=\"in_u1\")\n",
    "len_in_u2 = tf.placeholder(tf.int32, (), name=\"in_u1\")\n",
    "len_in_v2 = tf.placeholder(tf.int32, (), name=\"in_u1\")\n",
    "len_in_u3 = tf.placeholder(tf.int32, (), name=\"in_u1\")\n",
    "len_in_v3 = tf.placeholder(tf.int32, (), name=\"in_u1\")\n",
    "\n",
    "out_u1 = tf.placeholder(tf.int32, [None, max_time], name=\"out_u1\")\n",
    "out_v1 = tf.placeholder(tf.int32, [None, max_time], name=\"out_v1\")\n",
    "out_u2 = tf.placeholder(tf.int32, [None, max_time], name=\"out_u2\")\n",
    "\n",
    "len_out_u1\n",
    "...\n",
    "\n",
    "\n",
    "weights_ll = tf.placeholder(tf.float32, [None], name=\"wll\")\n",
    "weights_lu = tf.placeholder(tf.float32, [None], name=\"wlu\")\n",
    "weights_uu = tf.placeholder(tf.float32, [None], name=\"wuu\")\n",
    "\n",
    "cu1 = tf.placeholder(tf.float32, [None], name=\"CuLL\")\n",
    "cv1 = tf.placeholder(tf.float32, [None], name=\"CvLL\")\n",
    "cu2 = tf.placeholder(tf.float32, [None], name=\"CuLU\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Dummy(object):\n",
    "    pass\n",
    "\n",
    "def next_batch(h_edges, start, finish):\n",
    "    \"\"\"\n",
    "    Helper function for the iterator, note that the neural graph machines,\n",
    "    due to its unique loss function, requires carefully crafted inputs\n",
    "\n",
    "    Refer to the Neural Graph Machines paper, section 3 and 3.3 for more details\n",
    "    \"\"\"\n",
    "    edges_ll = list()\n",
    "    edges_lu = list()\n",
    "    edges_uu = list()\n",
    "    weights_ll = list()\n",
    "    weights_lu = list()\n",
    "    weights_uu = list()\n",
    "    batch_edges = h_edges[start:finish]\n",
    "    batch_edges = np.asarray(batch_edges)\n",
    "\n",
    "    for i, j in batch_edges[:]:\n",
    "        if (0 <= i < l) and (0 <= j < l):\n",
    "            edges_ll.append((i, j))\n",
    "            weights_ll.append(graph.get_edge_data(i,j)['weight'])\n",
    "        elif (0 <= i < l) and (l <= j < u):\n",
    "            edges_lu.append((i, j))\n",
    "            weights_lu.append(graph.get_edge_data(i,j)['weight'])\n",
    "        else:\n",
    "            edges_uu.append((i, j))\n",
    "            weights_uu.append(graph.get_edge_data(i,j)['weight'])\n",
    "    \n",
    "    if len(edges_ll)==0 or len(edges_lu)==0 or len(edges_uu)==0:\n",
    "        print(\"No matched data. Reset the batch\")\n",
    "        np.random.shuffle(h_edges[start:])\n",
    "        return next_batch(h_edges,start,finish)\n",
    "        \n",
    "\n",
    "    u_ll = [e[0] for e in edges_ll]\n",
    "\n",
    "    # number of incident edges for nodes u\n",
    "    c_ull = [1 / len(graph.edges(n)) for n in u_ll]\n",
    "    v_ll = [e[1] for e in edges_ll]\n",
    "    c_vll = [1 / len(graph.edges(n)) for n in v_ll]\n",
    "    nodes_ll_u = sources[u_ll]\n",
    "    \n",
    "    labels_ll_u = np.empty(len(u_ll), dtype=np.object)\n",
    "    labels_ll_u[:] = [label(n) for n in u_ll]\n",
    "    \n",
    "    nodes_ll_v = sources[v_ll]\n",
    "\n",
    "    labels_ll_v = np.empty(len(v_ll), dtype=np.object)\n",
    "    labels_ll_v[:] = [label(n) for n in v_ll]\n",
    "    \n",
    "    u_lu = [e[0] for e in edges_lu]\n",
    "    c_ulu = [1 / len(graph.edges(n)) for n in u_lu]\n",
    "    nodes_lu_u = sources[u_lu]\n",
    "    nodes_lu_v = sources[[e[1] for e in edges_lu]]\n",
    "\n",
    "    labels_lu = np.empty(len(u_lu), dtype=np.object)\n",
    "    labels_lu[:] = [label(n) for n in u_lu]\n",
    "    \n",
    "    nodes_uu_u = sources[[e[0] for e in edges_uu]]\n",
    "    nodes_uu_v = sources[[e[1] for e in edges_uu]]\n",
    "    \n",
    "    len_in_u1 = [np.min([len(x)+1, max_time]) for x in nodes_ll_u]\n",
    "    len_in_v1 = [np.min([len(x)+1, max_time]) for x in nodes_ll_v]\n",
    "    len_in_u2 = [np.min([len(x)+1, max_time]) for x in nodes_lu_u]\n",
    "    len_in_v2 = [np.min([len(x)+1, max_time]) for x in nodes_lu_v]\n",
    "    len_in_u3 = [np.min([len(x)+1, max_time]) for x in nodes_uu_u]\n",
    "    len_in_v3 = [np.min([len(x)+1, max_time]) for x in nodes_uu_v]\n",
    "    len_out_u1 = [np.min([len(x)+1, max_time]) for x in labels_ll_u]\n",
    "    len_out_v1 = [np.min([len(x)+1, max_time]) for x in labels_ll_v]\n",
    "    len_out_u2 = [np.min([len(x)+1, max_time]) for x in labels_lu]\n",
    "    \n",
    "    nodes_ll_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_ll_u]).T\n",
    "    nodes_ll_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_ll_v]).T\n",
    "    nodes_lu_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_lu_u]).T\n",
    "    nodes_lu_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_lu_v]).T\n",
    "    nodes_uu_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_uu_u]).T\n",
    "    nodes_uu_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_uu_v]).T\n",
    "    labels_ll_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in labels_ll_u]).T\n",
    "    labels_ll_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in labels_ll_v]).T\n",
    "    labels_lu = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in labels_lu]).T\n",
    "        \n",
    "    params = Dummy()\n",
    "    params.in_u1 = nodes_ll_u\n",
    "    params.in_v1 = nodes_ll_v\n",
    "    params.out_u1 = labels_ll_u\n",
    "    params.out_v1 = labels_ll_v\n",
    "    params.in_u3 = nodes_uu_u\n",
    "    params.in_v3 = nodes_uu_v\n",
    "    params.in_u2 = nodes_lu_u\n",
    "    params.in_v2 = nodes_lu_v\n",
    "    params.out_u2 = labels_lu\n",
    "    params.weights_ll = weights_ll\n",
    "    params.weights_lu = weights_lu\n",
    "    params.weights_uu = weights_uu\n",
    "    params.cu1 = c_ull\n",
    "    params.cv1 = c_vll\n",
    "    params.cu2 = c_ulu\n",
    "        \n",
    "    params.len_in_u1 = len_in_u1\n",
    "    params.len_in_v1 = len_in_v1\n",
    "    params.len_in_u2 = len_in_u2\n",
    "    params.len_in_v2 = len_in_v2\n",
    "    params.len_in_u3 = len_in_u3\n",
    "    params.len_in_v3 = len_in_v3\n",
    "    params.len_out_u1 = len_out_u1\n",
    "    params.len_out_v1 = len_out_v1\n",
    "    params.len_out_u2 = len_out_u2\n",
    "        \n",
    "    return params\n",
    "\n",
    "\n",
    "def batch_iter(batch_size):\n",
    "    \"\"\"\n",
    "        Generates a batch iterator for the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    data_size = len(graph.edges())\n",
    "\n",
    "    edges = np.random.permutation(graph.edges())\n",
    "\n",
    "    num_batches = int(data_size / batch_size)\n",
    "\n",
    "    if data_size % batch_size > 0:\n",
    "        num_batches = int(data_size / batch_size) + 1\n",
    "\n",
    "    batch_num = 0\n",
    "    while True:\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = (batch_num + 1) * batch_size\n",
    "        \n",
    "        if end_index > data_size:\n",
    "            print(\"rebatching...\")\n",
    "            batch_num = 0\n",
    "            edges = np.random.permutation(graph.edges())\n",
    "            start_index = 0\n",
    "            end_index = batch_size\n",
    "            \n",
    "        yield next_batch(edges,start_index,end_index)\n",
    "        batch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch = batch_iter(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "params = next(batch)\n",
    "print(params.in_u1[:,0])\n",
    "print(params.len_in_u1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Building the models\n",
    "\n",
    "# ## The Embedding\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "embedding_size = 512\n",
    "num_units = embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def initialization():\n",
    "    model = Dummy()\n",
    "    model.encoder_inputs = tf.placeholder('int32', [max_time, None], name='encoder_inputs')\n",
    "    model.targets = tf.placeholder('int32', [max_time, None], name='target')\n",
    "    model.decoder_inputs = tf.concat([tf.fill([1, tf.shape(model.targets)[1]], SOS_token), model.targets[:-1,:]], 0)\n",
    "    \n",
    "    model.source_sequence_lengths = tf.placeholder('int32', [None], name='source_sequence_lengths')\n",
    "    model.target_sequence_lengths = tf.placeholder('int32', [None], name='target_sequence_lengths')\n",
    "    \n",
    "    model.dropout = tf.placeholder('float32', [], name='dropout')\n",
    "    model.learning_rate = tf.placeholder('float32', [], name='learning_rate')\n",
    "    model.max_gradient_norm = tf.placeholder('float32', [], name='max_gradient_norm') # often set to a value like 5 or 1\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "model = initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def embedding(model):\n",
    "    with tf.variable_scope(\"embedding\", dtype='float32') as scope:\n",
    "        # Embedding\n",
    "        embedding_encoder = tf.get_variable(\"embedding_encoder\", [src_vocab_size, embedding_size])\n",
    "        embedding_decoder = tf.get_variable(\"embedding_decoder\", [tgt_vocab_size, embedding_size])\n",
    "        # Look up embedding:\n",
    "        #   encoder_inputs: [max_time, batch_size]\n",
    "        #   encoder_emp_inp: [max_time, batch_size, embedding_size]\n",
    "        encoder_emb_inp = tf.nn.embedding_lookup(embedding_encoder, model.encoder_inputs)\n",
    "        decoder_emb_inp = tf.nn.embedding_lookup(embedding_decoder, model.decoder_inputs)\n",
    "        \n",
    "        model.embedding_encoder = embedding_encoder\n",
    "        model.embedding_decoder = embedding_decoder\n",
    "        model.encoder_emb_inp = encoder_emb_inp\n",
    "        model.decoder_emb_inp = decoder_emb_inp\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "model = embedding(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ## The Encoder\n",
    "def encoder(model):\n",
    "    with tf.variable_scope(\"encoder\", dtype='float32') as scope:\n",
    "        # Build RNN cell\n",
    "        # Construct forward and backward cells\n",
    "        forward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "        forward_cell = tf.contrib.rnn.DropoutWrapper(cell=forward_cell, input_keep_prob=(1.0 - model.dropout))\n",
    "        backward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "        backward_cell = tf.contrib.rnn.DropoutWrapper(cell=backward_cell, input_keep_prob=(1.0 - model.dropout))\n",
    "\n",
    "        bi_outputs, bi_encoder_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "            forward_cell, backward_cell, model.encoder_emb_inp, dtype='float32',\n",
    "            sequence_length=model.source_sequence_lengths, time_major=True)\n",
    "        bi_encoder_outputs = tf.concat(bi_outputs, -1)\n",
    "        \n",
    "        encoder_outputs = bi_encoder_outputs\n",
    "        encoder_state = bi_encoder_state\n",
    "        \"\"\"\n",
    "        # Stacking encoders\n",
    "        encoder_cell = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "\n",
    "        # Run Dynamic RNN\n",
    "        #   encoder_outpus: [max_time, batch_size, num_units]\n",
    "        #   encoder_state: [batch_size, num_units]\n",
    "        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, bi_encoder_outputs, dtype='float32',\n",
    "            sequence_length=model.source_sequence_lengths, time_major=True)\n",
    "        \"\"\"        \n",
    "        model.encoder_outputs = encoder_outputs\n",
    "        model.encoder_state = encoder_state\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "model = encoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ## Decoder\n",
    "def decoder(model):\n",
    "    with tf.variable_scope(\"decoder\", dtype='float32') as scope:\n",
    "        \"\"\" Attention Mechanisms \"\"\"\n",
    "        # attention_states: [batch_size, max_time, num_units]\n",
    "        attention_states = tf.transpose(model.encoder_outputs, [1, 0, 2])\n",
    "\n",
    "        # Create an attention mechanism\n",
    "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units, attention_states, scale=True,\n",
    "            memory_sequence_length=model.source_sequence_lengths)\n",
    "\n",
    "        # Build RNN cell\n",
    "        cell_list = []\n",
    "        for i in range(2):\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell=cell, input_keep_prob=(1.0 - model.dropout))\n",
    "            cell_list.append(cell)\n",
    "        \n",
    "        decoder_cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "\n",
    "        decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism,\n",
    "            attention_layer_size=num_units, name=\"attention\")\n",
    "\n",
    "        decoder_initial_state = decoder_cell.zero_state(tf.shape(model.decoder_emb_inp)[1], 'float32').clone(cell_state=model.encoder_state)\n",
    "        \"\"\"\"\"\"\n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            model.decoder_emb_inp, model.target_sequence_lengths, time_major=True)\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, decoder_initial_state)\n",
    "        # Dynamic decoding\n",
    "        outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            output_time_major=True,\n",
    "            swap_memory=True,\n",
    "            scope=scope)\n",
    "\n",
    "        #projection\n",
    "        output_layer = layers_core.Dense(tgt_vocab_size, use_bias=False, name=\"output_projection\")\n",
    "        logits = output_layer(outputs.rnn_output)\n",
    "        \n",
    "    model.logits = logits\n",
    "    model.decoder_cell = decoder_cell\n",
    "    model.decoder_initial_state = decoder_initial_state\n",
    "    model.output_layer = output_layer\n",
    "    model.final_context_state = final_context_state\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "model = decoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = initialization()\n",
    "    model = embedding(model)\n",
    "    model = encoder(model)\n",
    "    model = decoder(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "    ngm = Dummy()\n",
    "    \n",
    "    ngm.model_u1 = create_model()\n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    ngm.model_v1 = create_model()\n",
    "    ngm.model_u2 = create_model()\n",
    "    ngm.model_v2 = create_model()\n",
    "    ngm.model_u3 = create_model()\n",
    "    ngm.model_v3 = create_model()\n",
    "    \n",
    "    ngm.alpha_ll = tf.constant(1., dtype=np.float32, name=\"alpha_ll\")\n",
    "    ngm.alpha_lu = tf.constant(1., dtype=np.float32, name=\"alpha_lu\")\n",
    "    ngm.alpha_uu = tf.constant(.5, dtype=np.float32, name=\"alpha_uu\")\n",
    "\n",
    "    ngm.weights_ll = tf.placeholder(tf.float32, [None], name=\"weights_ll\")\n",
    "    ngm.weights_lu = tf.placeholder(tf.float32, [None], name=\"weights_lu\")\n",
    "    ngm.weights_uu = tf.placeholder(tf.float32, [None], name=\"weights_uu\")\n",
    "\n",
    "    ngm.cu_ll = tf.placeholder(tf.float32, [None], name=\"cu_ll\")\n",
    "    ngm.cv_ll = tf.placeholder(tf.float32, [None], name=\"cv_ll\")\n",
    "    ngm.cu_lu = tf.placeholder(tf.float32, [None], name=\"cu_lu\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vanilla_loss(model):\n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights, 0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def distance_loss(model1, model2):\n",
    "    scores_u = tf.concat((model1.final_context_state.cell_state[0].c, model1.final_context_state.cell_state[1].c), 1)\n",
    "    scores_v = tf.concat((model2.final_context_state.cell_state[0].c, model2.final_context_state.cell_state[1].c), 1)\n",
    "    \n",
    "    beta = 0.97\n",
    "    exp_mov_avg = tf.get_variable('exp_mov_avg', shape=[embedding_size*2], initializer=tf.constant_initializer(0.))\n",
    "    exp_mov_var = tf.get_variable('exp_mov_var', shape=[embedding_size*2], initializer=tf.constant_initializer(0.))\n",
    "    \n",
    "    exp_mov_avg = exp_mov_avg.assign_sub((exp_mov_avg-tf.reduce_mean(tf.concat((scores_u, scores_v), 0), 0)) * (1 - beta)) \n",
    "    exp_mov_var = exp_mov_var.assign_sub((exp_mov_var-tf.square(exp_mov_avg)) * (1 - beta))\n",
    "    \n",
    "    #t = scores_u - scores_v\n",
    "    #loss = tf.square(scores_u - scores_v)\n",
    "    #loss = tf.reduce_sum(loss, 1)\n",
    "    \n",
    "    #loss = 1 - (tf.reduce_sum(tf.multiply(scores_u, scores_v), axis=1) / (tf.norm(scores_u, axis=1) * tf.norm(scores_v, axis=1)))\n",
    "    \n",
    "    loss = tf.pow(tf.reduce_sum(tf.square(scores_u-scores_v) / (exp_mov_var + 1e-4), 1), 0.5)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ngm_optimizer(ngm):\n",
    "\n",
    "    l_vanilla = tf.reduce_mean(ngm.cu_ll * vanilla_loss(ngm.model_u1))\n",
    "    l_vanilla += tf.reduce_mean(ngm.cv_ll * vanilla_loss(ngm.model_v1))\n",
    "    l_vanilla += tf.reduce_mean(ngm.cu_lu * vanilla_loss(ngm.model_u2))\n",
    "\n",
    "    with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "        l_dist1 = ngm.alpha_ll * ngm.weights_ll * distance_loss(ngm.model_u1, ngm.model_v1)\n",
    "        scope.reuse_variables()\n",
    "        l_dist2 = ngm.alpha_lu * ngm.weights_lu * distance_loss(ngm.model_u2, ngm.model_v2)\n",
    "        l_dist3 = ngm.alpha_uu * ngm.weights_uu * distance_loss(ngm.model_u3, ngm.model_v3)\n",
    "    ratio = 1\n",
    "    l_dist = (tf.reduce_mean(l_dist1) + tf.reduce_mean(l_dist2) + tf.reduce_mean(l_dist3)) * ratio\n",
    "    \n",
    "    loss = l_vanilla + l_dist\n",
    "    \n",
    "    # Calculate and clip gradients\n",
    "    parameters = tf.trainable_variables()\n",
    "    gradients = tf.gradients(loss, parameters)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, ngm.model_u1.max_gradient_norm)\n",
    "\n",
    "    # Optimization\n",
    "    optimizer = tf.train.GradientDescentOptimizer(ngm.model_u1.learning_rate)\n",
    "    update_step = optimizer.apply_gradients(zip(clipped_gradients, parameters))\n",
    "    \n",
    "    ngm.l_vanilla = l_vanilla\n",
    "    ngm.l_dist = l_dist\n",
    "    ngm.loss = loss\n",
    "    ngm.update_step = update_step\n",
    "    \n",
    "    return ngm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ngm = ngm_optimizer(ngm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ## Running training\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, './log/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ls_vanilla, ls_dist = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "for i in range(1):\n",
    "    params = next(batch)\n",
    "    src_seq_l, tgt_seq_l, ss, ts = params.len_in_u1, params.len_out_u1, params.in_u1, params.out_u1\n",
    "\n",
    "    feed_dict={model.learning_rate: 1.,\n",
    "               model.dropout: .2,\n",
    "               model.max_gradient_norm: 5,\n",
    "               model.source_sequence_lengths: src_seq_l,\n",
    "               model.target_sequence_lengths:tgt_seq_l,\n",
    "               model.encoder_inputs: ss,\n",
    "               model.targets: ts}\n",
    "\n",
    "\n",
    "    _, l_val = sess.run([model.update_step, model.loss], feed_dict=feed_dict)\n",
    "    ls.append(l_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch = batch_iter(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "t_str = time()\n",
    "for i in range(1000):\n",
    "    params = next(batch)\n",
    "    \n",
    "    feed_dict={ngm.model_u1.learning_rate: 1.,\n",
    "               ngm.model_u1.max_gradient_norm: 5,\n",
    "               ngm.weights_ll: params.weights_ll,\n",
    "               ngm.weights_lu: params.weights_lu,\n",
    "               ngm.weights_uu: params.weights_uu,\n",
    "               ngm.cu_ll: params.cu1,\n",
    "               ngm.cv_ll: params.cv1,\n",
    "               ngm.cu_lu: params.cu2,\n",
    "               \n",
    "               ngm.model_u1.dropout: .2,\n",
    "               ngm.model_v1.dropout: .2,\n",
    "               ngm.model_u2.dropout: .2,\n",
    "               ngm.model_v2.dropout: .2,\n",
    "               ngm.model_u3.dropout: .2,\n",
    "               ngm.model_v3.dropout: .2,\n",
    "               \n",
    "               ngm.model_u1.source_sequence_lengths: params.len_in_u1,\n",
    "               ngm.model_u1.target_sequence_lengths: params.len_out_u1,\n",
    "               ngm.model_u1.encoder_inputs: params.in_u1,\n",
    "               ngm.model_u1.targets: params.out_u1,\n",
    "               \n",
    "               ngm.model_v1.source_sequence_lengths: params.len_in_v1,\n",
    "               ngm.model_v1.target_sequence_lengths: params.len_out_v1,\n",
    "               ngm.model_v1.encoder_inputs: params.in_v1,\n",
    "               ngm.model_v1.targets: params.out_v1,\n",
    "               \n",
    "               ngm.model_u2.source_sequence_lengths: params.len_in_u2,\n",
    "               ngm.model_u2.target_sequence_lengths: params.len_out_u2,\n",
    "               ngm.model_u2.encoder_inputs: params.in_u2,\n",
    "               ngm.model_u2.targets: params.out_u2,\n",
    "               \n",
    "               ngm.model_v2.source_sequence_lengths: params.len_in_v2,\n",
    "               ngm.model_v2.target_sequence_lengths: np.ones(params.in_v2.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v2.encoder_inputs: params.in_v2,\n",
    "               ngm.model_v2.targets: np.ones((max_time, params.in_v2.shape[1]), 'int32') * EOS_token,\n",
    "\n",
    "               ngm.model_u3.source_sequence_lengths: params.len_in_u3,\n",
    "               ngm.model_u3.target_sequence_lengths: np.ones(params.in_u3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_u3.encoder_inputs: params.in_u3,\n",
    "               ngm.model_u3.targets: np.ones((max_time, params.in_u3.shape[1]), 'int32') * EOS_token,\n",
    "               \n",
    "               ngm.model_v3.source_sequence_lengths: params.len_in_v3,\n",
    "               ngm.model_v3.target_sequence_lengths: np.ones(params.in_v3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v3.encoder_inputs: params.in_v3,\n",
    "               ngm.model_v3.targets: np.ones((max_time, params.in_v3.shape[1]), 'int32') * EOS_token\n",
    "               }\n",
    "\n",
    "\n",
    "    _, l_v, l_d = sess.run([ngm.update_step, ngm.l_vanilla, ngm.l_dist], feed_dict=feed_dict)\n",
    "    ls_vanilla.append(l_v)\n",
    "    ls_dist.append(l_d)\n",
    "    if (i % 10 == 0):\n",
    "        view_str_idx = 0\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.plot(np.arange(len(ls_vanilla)-view_str_idx)+view_str_idx, ls_vanilla[view_str_idx:], np.arange(len(ls_dist)-view_str_idx)+view_str_idx, np.array(ls_dist[view_str_idx:]))\n",
    "        plt.ylim(0,220)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "    #print(i, end='\\r')\n",
    "print(time() - t_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './log/ngm_256.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "ls_file = open('./ngm_256_ls.txt', 'w')\n",
    "\n",
    "for i in range(len(ls_vanilla)):\n",
    "    ls_file.write(\"%f\\t%f\\n\" % (ls_vanilla[i], ls_dist[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bleu import _bleu_online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def arr2stn(vocab, sentences):\n",
    "    def foo_iter(stn):\n",
    "        try:\n",
    "            end_idx = stn.index(EOS_token)\n",
    "        except:\n",
    "            end_idx = len(stn)\n",
    "        return ' '.join([idx2word(vocab, word) for word in stn[:end_idx]])\n",
    "    \n",
    "    sentences = sentences.tolist()\n",
    "    ret = []\n",
    "    \n",
    "    if len(sentences)==0:\n",
    "        stn = sentences\n",
    "        ret.append(foo_iter(stn))\n",
    "        \n",
    "    else:\n",
    "        for stn in sentences:\n",
    "            ret.append(foo_iter(stn))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_it(batch_size, sources, targets, ending=False):\n",
    "    \"\"\"\n",
    "        Generates a batch iterator for the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    data_size = len(sources)\n",
    "\n",
    "    rand_inds = np.random.permutation(np.arange(data_size))\n",
    "\n",
    "    num_batches = int(data_size / batch_size)\n",
    "\n",
    "    if data_size % batch_size > 0:\n",
    "        num_batches = int(data_size / batch_size) + 1\n",
    "\n",
    "    batch_num = 0\n",
    "    end_flag = False\n",
    "    while True:\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = (batch_num + 1) * batch_size\n",
    "        \n",
    "        if end_index > data_size:\n",
    "            if ending:\n",
    "                end_flag = True\n",
    "            else: \n",
    "                print('rebatching...')\n",
    "                batch_num = 0\n",
    "                rand_inds = np.random.permutation(rand_inds)\n",
    "                start_index = 0\n",
    "                end_index = batch_size\n",
    "        \n",
    "        \n",
    "        srcs = sources[rand_inds[start_index:end_index]]\n",
    "        tgts = targets[rand_inds[start_index:end_index]]\n",
    "        source_sequence_lengths = np.array([np.min([len(x)+1, max_time]) for x in srcs])\n",
    "        target_sequence_lengths = np.array([np.min([len(x)+1, max_time]) for x in tgts])\n",
    "        \n",
    "        srcs = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in srcs])\n",
    "        tgts = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in tgts])\n",
    "        \n",
    "        srcs = srcs.T\n",
    "        tgts = tgts.T\n",
    "        \n",
    "        params = Dummy()\n",
    "        params.source_sequence_lengths = source_sequence_lengths\n",
    "        params.target_sequence_lengths = target_sequence_lengths\n",
    "        params.sources = srcs\n",
    "        params.targets = tgts\n",
    "        \n",
    "        yield params\n",
    "        \n",
    "        if end_flag:\n",
    "            return\n",
    "        \n",
    "        batch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Evaluating the network\n",
    "def evaluation(model):\n",
    "    # In[34]:\n",
    "\n",
    "    model.maximum_iterations = tf.round(tf.reduce_max(model.source_sequence_lengths) * 2)\n",
    "\n",
    "\n",
    "    # In[35]:\n",
    "\n",
    "    with tf.variable_scope('decoder', reuse=True) as scope:\n",
    "    # Dynamic decoding\n",
    "        # Helper\n",
    "        helper_eval = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            model.embedding_decoder, tf.fill([tf.shape(model.decoder_emb_inp)[1]], SOS_token),\n",
    "            EOS_token)\n",
    "        # Decoder\n",
    "        decoder_eval = tf.contrib.seq2seq.BasicDecoder(\n",
    "            model.decoder_cell, helper_eval, model.decoder_initial_state,\n",
    "            output_layer=model.output_layer)\n",
    "\n",
    "        outputs_eval, final_context_state_eval, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder_eval, maximum_iterations=model.maximum_iterations,\n",
    "            swap_memory=True, scope=scope)\n",
    "\n",
    "        model.logits_eval = outputs_eval.rnn_output\n",
    "        \n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(tf.shape(model.decoder_emb_inp)[1])\n",
    "    \n",
    "    model.loss_eval = loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = evaluation(ngm.model_u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./nmt_data/tst2012.en', 'r') as f:\n",
    "    sources_val = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "sources_val = np.array(sources_val)\n",
    "\n",
    "with open('./nmt_data/tst2012.vi', 'r') as f:\n",
    "    targets_val = [[word2idx(tgt_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "targets_val = np.array(targets_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\r"
     ]
    }
   ],
   "source": [
    "t_str = time()\n",
    "display.clear_output(wait=False)\n",
    "f, axarr = plt.subplots(1, 2, figsize=(20,10))\n",
    "for i in range(12000):\n",
    "    params = next(batch)\n",
    "    \n",
    "    feed_dict={ngm.model_u1.learning_rate: 1.,\n",
    "               ngm.model_u1.max_gradient_norm: 5,\n",
    "               ngm.weights_ll: params.weights_ll,\n",
    "               ngm.weights_lu: params.weights_lu,\n",
    "               ngm.weights_uu: params.weights_uu,\n",
    "               ngm.cu_ll: params.cu1,\n",
    "               ngm.cv_ll: params.cv1,\n",
    "               ngm.cu_lu: params.cu2,\n",
    "               \n",
    "               ngm.model_u1.dropout: .2,\n",
    "               ngm.model_v1.dropout: .2,\n",
    "               ngm.model_u2.dropout: .2,\n",
    "               ngm.model_v2.dropout: .2,\n",
    "               ngm.model_u3.dropout: .2,\n",
    "               ngm.model_v3.dropout: .2,\n",
    "               \n",
    "               ngm.model_u1.source_sequence_lengths: params.len_in_u1,\n",
    "               ngm.model_u1.target_sequence_lengths: params.len_out_u1,\n",
    "               ngm.model_u1.encoder_inputs: params.in_u1,\n",
    "               ngm.model_u1.targets: params.out_u1,\n",
    "               \n",
    "               ngm.model_v1.source_sequence_lengths: params.len_in_v1,\n",
    "               ngm.model_v1.target_sequence_lengths: params.len_out_v1,\n",
    "               ngm.model_v1.encoder_inputs: params.in_v1,\n",
    "               ngm.model_v1.targets: params.out_v1,\n",
    "               \n",
    "               ngm.model_u2.source_sequence_lengths: params.len_in_u2,\n",
    "               ngm.model_u2.target_sequence_lengths: params.len_out_u2,\n",
    "               ngm.model_u2.encoder_inputs: params.in_u2,\n",
    "               ngm.model_u2.targets: params.out_u2,\n",
    "               \n",
    "               ngm.model_v2.source_sequence_lengths: params.len_in_v2,\n",
    "               ngm.model_v2.target_sequence_lengths: np.ones(params.in_v2.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v2.encoder_inputs: params.in_v2,\n",
    "               ngm.model_v2.targets: np.ones((max_time, params.in_v2.shape[1]), 'int32') * EOS_token,\n",
    "\n",
    "               ngm.model_u3.source_sequence_lengths: params.len_in_u3,\n",
    "               ngm.model_u3.target_sequence_lengths: np.ones(params.in_u3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_u3.encoder_inputs: params.in_u3,\n",
    "               ngm.model_u3.targets: np.ones((max_time, params.in_u3.shape[1]), 'int32') * EOS_token,\n",
    "               \n",
    "               ngm.model_v3.source_sequence_lengths: params.len_in_v3,\n",
    "               ngm.model_v3.target_sequence_lengths: np.ones(params.in_v3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v3.encoder_inputs: params.in_v3,\n",
    "               ngm.model_v3.targets: np.ones((max_time, params.in_v3.shape[1]), 'int32') * EOS_token\n",
    "               }\n",
    "\n",
    "\n",
    "    _, l_v, l_d = sess.run([ngm.update_step, ngm.l_vanilla, ngm.l_dist], feed_dict=feed_dict)\n",
    "    ls_vanilla.append(l_v)\n",
    "    ls_dist.append(l_d)\n",
    "    #if (i % 10 == 0):\n",
    "        #view_str_idx = 23000\n",
    "        #axarr[0].set_color_cycle(['blue', 'orange'])\n",
    "        #axarr[0].plot(np.arange(len(ls_vanilla)-view_str_idx)+view_str_idx, ls_vanilla[view_str_idx:], np.arange(len(ls_dist)-view_str_idx)+view_str_idx, np.array(ls_dist[view_str_idx:]))\n",
    "        #axarr[0].set_ylim(0,75)\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    if (i % 100 == 0):\n",
    "        batch_val = batch_it(128, sources_val, targets_val, ending=True)\n",
    "        tmp_vals = []\n",
    "        for params in batch_val:\n",
    "            feed_dict_test={model.dropout: 0.,\n",
    "                            model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                            model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                            model.encoder_inputs: params.sources,\n",
    "                            model.targets: params.targets}\n",
    "            tmp_vals.append(sess.run(model.loss_eval, feed_dict_test))\n",
    "        res.append(np.mean(tmp_vals))\n",
    "        #axarr[1].plot(np.arange(len(res[80:])), res[80:], color='brown')\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    print(i, end='\\r')\n",
    "print(time() - t_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t_str = time()\n",
    "for i in range(1500):\n",
    "    params = next(batch)\n",
    "    \n",
    "    feed_dict={ngm.model_u1.learning_rate: .5,\n",
    "               ngm.model_u1.max_gradient_norm: 5,\n",
    "               ngm.weights_ll: params.weights_ll,\n",
    "               ngm.weights_lu: params.weights_lu,\n",
    "               ngm.weights_uu: params.weights_uu,\n",
    "               ngm.cu_ll: params.cu1,\n",
    "               ngm.cv_ll: params.cv1,\n",
    "               ngm.cu_lu: params.cu2,\n",
    "               \n",
    "               ngm.model_u1.dropout: .2,\n",
    "               ngm.model_v1.dropout: .2,\n",
    "               ngm.model_u2.dropout: .2,\n",
    "               ngm.model_v2.dropout: .2,\n",
    "               ngm.model_u3.dropout: .2,\n",
    "               ngm.model_v3.dropout: .2,\n",
    "               \n",
    "               ngm.model_u1.source_sequence_lengths: params.len_in_u1,\n",
    "               ngm.model_u1.target_sequence_lengths: params.len_out_u1,\n",
    "               ngm.model_u1.encoder_inputs: params.in_u1,\n",
    "               ngm.model_u1.targets: params.out_u1,\n",
    "               \n",
    "               ngm.model_v1.source_sequence_lengths: params.len_in_v1,\n",
    "               ngm.model_v1.target_sequence_lengths: params.len_out_v1,\n",
    "               ngm.model_v1.encoder_inputs: params.in_v1,\n",
    "               ngm.model_v1.targets: params.out_v1,\n",
    "               \n",
    "               ngm.model_u2.source_sequence_lengths: params.len_in_u2,\n",
    "               ngm.model_u2.target_sequence_lengths: params.len_out_u2,\n",
    "               ngm.model_u2.encoder_inputs: params.in_u2,\n",
    "               ngm.model_u2.targets: params.out_u2,\n",
    "               \n",
    "               ngm.model_v2.source_sequence_lengths: params.len_in_v2,\n",
    "               ngm.model_v2.target_sequence_lengths: np.ones(params.in_v2.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v2.encoder_inputs: params.in_v2,\n",
    "               ngm.model_v2.targets: np.ones((max_time, params.in_v2.shape[1]), 'int32') * EOS_token,\n",
    "\n",
    "               ngm.model_u3.source_sequence_lengths: params.len_in_u3,\n",
    "               ngm.model_u3.target_sequence_lengths: np.ones(params.in_u3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_u3.encoder_inputs: params.in_u3,\n",
    "               ngm.model_u3.targets: np.ones((max_time, params.in_u3.shape[1]), 'int32') * EOS_token,\n",
    "               \n",
    "               ngm.model_v3.source_sequence_lengths: params.len_in_v3,\n",
    "               ngm.model_v3.target_sequence_lengths: np.ones(params.in_v3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v3.encoder_inputs: params.in_v3,\n",
    "               ngm.model_v3.targets: np.ones((max_time, params.in_v3.shape[1]), 'int32') * EOS_token\n",
    "               }\n",
    "\n",
    "\n",
    "    _, l_v, l_d = sess.run([ngm.update_step, ngm.l_vanilla, ngm.l_dist], feed_dict=feed_dict)\n",
    "    ls_vanilla.append(l_v)\n",
    "    ls_dist.append(l_d)\n",
    "    #if (i % 10 == 0):\n",
    "        #view_str_idx = 23000\n",
    "        #axarr[0].set_color_cycle(['blue', 'orange'])\n",
    "        #axarr[0].plot(np.arange(len(ls_vanilla)-view_str_idx)+view_str_idx, ls_vanilla[view_str_idx:], np.arange(len(ls_dist)-view_str_idx)+view_str_idx, np.array(ls_dist[view_str_idx:]))\n",
    "        #axarr[0].set_ylim(0,75)\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    if (i % 100 == 0):\n",
    "        batch_val = batch_it(128, sources_val, targets_val, ending=True)\n",
    "        tmp_vals = []\n",
    "        for params in batch_val:\n",
    "            feed_dict_test={model.dropout: 0.,\n",
    "                            model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                            model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                            model.encoder_inputs: params.sources,\n",
    "                            model.targets: params.targets}\n",
    "            tmp_vals.append(sess.run(model.loss_eval, feed_dict_test))\n",
    "        res.append(np.mean(tmp_vals))\n",
    "        #axarr[1].plot(np.arange(len(res[80:])), res[80:], color='brown')\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    print(i, end='\\r')\n",
    "print(time() - t_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t_str = time()\n",
    "for i in range(1500):\n",
    "    params = next(batch)\n",
    "    \n",
    "    feed_dict={ngm.model_u1.learning_rate: .25,\n",
    "               ngm.model_u1.max_gradient_norm: 5,\n",
    "               ngm.weights_ll: params.weights_ll,\n",
    "               ngm.weights_lu: params.weights_lu,\n",
    "               ngm.weights_uu: params.weights_uu,\n",
    "               ngm.cu_ll: params.cu1,\n",
    "               ngm.cv_ll: params.cv1,\n",
    "               ngm.cu_lu: params.cu2,\n",
    "               \n",
    "               ngm.model_u1.dropout: .2,\n",
    "               ngm.model_v1.dropout: .2,\n",
    "               ngm.model_u2.dropout: .2,\n",
    "               ngm.model_v2.dropout: .2,\n",
    "               ngm.model_u3.dropout: .2,\n",
    "               ngm.model_v3.dropout: .2,\n",
    "               \n",
    "               ngm.model_u1.source_sequence_lengths: params.len_in_u1,\n",
    "               ngm.model_u1.target_sequence_lengths: params.len_out_u1,\n",
    "               ngm.model_u1.encoder_inputs: params.in_u1,\n",
    "               ngm.model_u1.targets: params.out_u1,\n",
    "               \n",
    "               ngm.model_v1.source_sequence_lengths: params.len_in_v1,\n",
    "               ngm.model_v1.target_sequence_lengths: params.len_out_v1,\n",
    "               ngm.model_v1.encoder_inputs: params.in_v1,\n",
    "               ngm.model_v1.targets: params.out_v1,\n",
    "               \n",
    "               ngm.model_u2.source_sequence_lengths: params.len_in_u2,\n",
    "               ngm.model_u2.target_sequence_lengths: params.len_out_u2,\n",
    "               ngm.model_u2.encoder_inputs: params.in_u2,\n",
    "               ngm.model_u2.targets: params.out_u2,\n",
    "               \n",
    "               ngm.model_v2.source_sequence_lengths: params.len_in_v2,\n",
    "               ngm.model_v2.target_sequence_lengths: np.ones(params.in_v2.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v2.encoder_inputs: params.in_v2,\n",
    "               ngm.model_v2.targets: np.ones((max_time, params.in_v2.shape[1]), 'int32') * EOS_token,\n",
    "\n",
    "               ngm.model_u3.source_sequence_lengths: params.len_in_u3,\n",
    "               ngm.model_u3.target_sequence_lengths: np.ones(params.in_u3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_u3.encoder_inputs: params.in_u3,\n",
    "               ngm.model_u3.targets: np.ones((max_time, params.in_u3.shape[1]), 'int32') * EOS_token,\n",
    "               \n",
    "               ngm.model_v3.source_sequence_lengths: params.len_in_v3,\n",
    "               ngm.model_v3.target_sequence_lengths: np.ones(params.in_v3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v3.encoder_inputs: params.in_v3,\n",
    "               ngm.model_v3.targets: np.ones((max_time, params.in_v3.shape[1]), 'int32') * EOS_token\n",
    "               }\n",
    "\n",
    "\n",
    "    _, l_v, l_d = sess.run([ngm.update_step, ngm.l_vanilla, ngm.l_dist], feed_dict=feed_dict)\n",
    "    ls_vanilla.append(l_v)\n",
    "    ls_dist.append(l_d)\n",
    "    #if (i % 10 == 0):\n",
    "        #view_str_idx = 23000\n",
    "        #axarr[0].set_color_cycle(['blue', 'orange'])\n",
    "        #axarr[0].plot(np.arange(len(ls_vanilla)-view_str_idx)+view_str_idx, ls_vanilla[view_str_idx:], np.arange(len(ls_dist)-view_str_idx)+view_str_idx, np.array(ls_dist[view_str_idx:]))\n",
    "        #axarr[0].set_ylim(0,75)\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    if (i % 100 == 0):\n",
    "        batch_val = batch_it(128, sources_val, targets_val, ending=True)\n",
    "        tmp_vals = []\n",
    "        for params in batch_val:\n",
    "            feed_dict_test={model.dropout: 0.,\n",
    "                            model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                            model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                            model.encoder_inputs: params.sources,\n",
    "                            model.targets: params.targets}\n",
    "            tmp_vals.append(sess.run(model.loss_eval, feed_dict_test))\n",
    "        res.append(np.mean(tmp_vals))\n",
    "        #axarr[1].plot(np.arange(len(res[80:])), res[80:], color='brown')\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    print(i, end='\\r')\n",
    "print(time() - t_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t_str = time()\n",
    "for i in range(1500):\n",
    "    params = next(batch)\n",
    "    \n",
    "    feed_dict={ngm.model_u1.learning_rate: .125,\n",
    "               ngm.model_u1.max_gradient_norm: 5,\n",
    "               ngm.weights_ll: params.weights_ll,\n",
    "               ngm.weights_lu: params.weights_lu,\n",
    "               ngm.weights_uu: params.weights_uu,\n",
    "               ngm.cu_ll: params.cu1,\n",
    "               ngm.cv_ll: params.cv1,\n",
    "               ngm.cu_lu: params.cu2,\n",
    "               \n",
    "               ngm.model_u1.dropout: .2,\n",
    "               ngm.model_v1.dropout: .2,\n",
    "               ngm.model_u2.dropout: .2,\n",
    "               ngm.model_v2.dropout: .2,\n",
    "               ngm.model_u3.dropout: .2,\n",
    "               ngm.model_v3.dropout: .2,\n",
    "               \n",
    "               ngm.model_u1.source_sequence_lengths: params.len_in_u1,\n",
    "               ngm.model_u1.target_sequence_lengths: params.len_out_u1,\n",
    "               ngm.model_u1.encoder_inputs: params.in_u1,\n",
    "               ngm.model_u1.targets: params.out_u1,\n",
    "               \n",
    "               ngm.model_v1.source_sequence_lengths: params.len_in_v1,\n",
    "               ngm.model_v1.target_sequence_lengths: params.len_out_v1,\n",
    "               ngm.model_v1.encoder_inputs: params.in_v1,\n",
    "               ngm.model_v1.targets: params.out_v1,\n",
    "               \n",
    "               ngm.model_u2.source_sequence_lengths: params.len_in_u2,\n",
    "               ngm.model_u2.target_sequence_lengths: params.len_out_u2,\n",
    "               ngm.model_u2.encoder_inputs: params.in_u2,\n",
    "               ngm.model_u2.targets: params.out_u2,\n",
    "               \n",
    "               ngm.model_v2.source_sequence_lengths: params.len_in_v2,\n",
    "               ngm.model_v2.target_sequence_lengths: np.ones(params.in_v2.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v2.encoder_inputs: params.in_v2,\n",
    "               ngm.model_v2.targets: np.ones((max_time, params.in_v2.shape[1]), 'int32') * EOS_token,\n",
    "\n",
    "               ngm.model_u3.source_sequence_lengths: params.len_in_u3,\n",
    "               ngm.model_u3.target_sequence_lengths: np.ones(params.in_u3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_u3.encoder_inputs: params.in_u3,\n",
    "               ngm.model_u3.targets: np.ones((max_time, params.in_u3.shape[1]), 'int32') * EOS_token,\n",
    "               \n",
    "               ngm.model_v3.source_sequence_lengths: params.len_in_v3,\n",
    "               ngm.model_v3.target_sequence_lengths: np.ones(params.in_v3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v3.encoder_inputs: params.in_v3,\n",
    "               ngm.model_v3.targets: np.ones((max_time, params.in_v3.shape[1]), 'int32') * EOS_token\n",
    "               }\n",
    "\n",
    "\n",
    "    _, l_v, l_d = sess.run([ngm.update_step, ngm.l_vanilla, ngm.l_dist], feed_dict=feed_dict)\n",
    "    ls_vanilla.append(l_v)\n",
    "    ls_dist.append(l_d)\n",
    "    #if (i % 10 == 0):\n",
    "        #view_str_idx = 23000\n",
    "        #axarr[0].set_color_cycle(['blue', 'orange'])\n",
    "        #axarr[0].plot(np.arange(len(ls_vanilla)-view_str_idx)+view_str_idx, ls_vanilla[view_str_idx:], np.arange(len(ls_dist)-view_str_idx)+view_str_idx, np.array(ls_dist[view_str_idx:]))\n",
    "        #axarr[0].set_ylim(0,75)\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    if (i % 100 == 0):\n",
    "        batch_val = batch_it(128, sources_val, targets_val, ending=True)\n",
    "        tmp_vals = []\n",
    "        for params in batch_val:\n",
    "            feed_dict_test={model.dropout: 0.,\n",
    "                            model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                            model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                            model.encoder_inputs: params.sources,\n",
    "                            model.targets: params.targets}\n",
    "            tmp_vals.append(sess.run(model.loss_eval, feed_dict_test))\n",
    "        res.append(np.mean(tmp_vals))\n",
    "        #axarr[1].plot(np.arange(len(res[80:])), res[80:], color='brown')\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    print(i, end='\\r')\n",
    "print(time() - t_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t_str = time()\n",
    "for i in range(1500):\n",
    "    params = next(batch)\n",
    "    \n",
    "    feed_dict={ngm.model_u1.learning_rate: .0625,\n",
    "               ngm.model_u1.max_gradient_norm: 5,\n",
    "               ngm.weights_ll: params.weights_ll,\n",
    "               ngm.weights_lu: params.weights_lu,\n",
    "               ngm.weights_uu: params.weights_uu,\n",
    "               ngm.cu_ll: params.cu1,\n",
    "               ngm.cv_ll: params.cv1,\n",
    "               ngm.cu_lu: params.cu2,\n",
    "               \n",
    "               ngm.model_u1.dropout: .2,\n",
    "               ngm.model_v1.dropout: .2,\n",
    "               ngm.model_u2.dropout: .2,\n",
    "               ngm.model_v2.dropout: .2,\n",
    "               ngm.model_u3.dropout: .2,\n",
    "               ngm.model_v3.dropout: .2,\n",
    "               \n",
    "               ngm.model_u1.source_sequence_lengths: params.len_in_u1,\n",
    "               ngm.model_u1.target_sequence_lengths: params.len_out_u1,\n",
    "               ngm.model_u1.encoder_inputs: params.in_u1,\n",
    "               ngm.model_u1.targets: params.out_u1,\n",
    "               \n",
    "               ngm.model_v1.source_sequence_lengths: params.len_in_v1,\n",
    "               ngm.model_v1.target_sequence_lengths: params.len_out_v1,\n",
    "               ngm.model_v1.encoder_inputs: params.in_v1,\n",
    "               ngm.model_v1.targets: params.out_v1,\n",
    "               \n",
    "               ngm.model_u2.source_sequence_lengths: params.len_in_u2,\n",
    "               ngm.model_u2.target_sequence_lengths: params.len_out_u2,\n",
    "               ngm.model_u2.encoder_inputs: params.in_u2,\n",
    "               ngm.model_u2.targets: params.out_u2,\n",
    "               \n",
    "               ngm.model_v2.source_sequence_lengths: params.len_in_v2,\n",
    "               ngm.model_v2.target_sequence_lengths: np.ones(params.in_v2.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v2.encoder_inputs: params.in_v2,\n",
    "               ngm.model_v2.targets: np.ones((max_time, params.in_v2.shape[1]), 'int32') * EOS_token,\n",
    "\n",
    "               ngm.model_u3.source_sequence_lengths: params.len_in_u3,\n",
    "               ngm.model_u3.target_sequence_lengths: np.ones(params.in_u3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_u3.encoder_inputs: params.in_u3,\n",
    "               ngm.model_u3.targets: np.ones((max_time, params.in_u3.shape[1]), 'int32') * EOS_token,\n",
    "               \n",
    "               ngm.model_v3.source_sequence_lengths: params.len_in_v3,\n",
    "               ngm.model_v3.target_sequence_lengths: np.ones(params.in_v3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v3.encoder_inputs: params.in_v3,\n",
    "               ngm.model_v3.targets: np.ones((max_time, params.in_v3.shape[1]), 'int32') * EOS_token\n",
    "               }\n",
    "\n",
    "\n",
    "    _, l_v, l_d = sess.run([ngm.update_step, ngm.l_vanilla, ngm.l_dist], feed_dict=feed_dict)\n",
    "    ls_vanilla.append(l_v)\n",
    "    ls_dist.append(l_d)\n",
    "    #if (i % 10 == 0):\n",
    "        #view_str_idx = 23000\n",
    "        #axarr[0].set_color_cycle(['blue', 'orange'])\n",
    "        #axarr[0].plot(np.arange(len(ls_vanilla)-view_str_idx)+view_str_idx, ls_vanilla[view_str_idx:], np.arange(len(ls_dist)-view_str_idx)+view_str_idx, np.array(ls_dist[view_str_idx:]))\n",
    "        #axarr[0].set_ylim(0,75)\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    if (i % 100 == 0):\n",
    "        batch_val = batch_it(128, sources_val, targets_val, ending=True)\n",
    "        tmp_vals = []\n",
    "        for params in batch_val:\n",
    "            feed_dict_test={model.dropout: 0.,\n",
    "                            model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                            model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                            model.encoder_inputs: params.sources,\n",
    "                            model.targets: params.targets}\n",
    "            tmp_vals.append(sess.run(model.loss_eval, feed_dict_test))\n",
    "        res.append(np.mean(tmp_vals))\n",
    "        #axarr[1].plot(np.arange(len(res[80:])), res[80:], color='brown')\n",
    "        #display.display(f)\n",
    "        #display.clear_output(wait=True)\n",
    "    print(i, end='\\r')\n",
    "print(time() - t_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './log/ngm_512_mahalanobis.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ls_file = open('./ngm_512_mahalanobis_ls.txt', 'w')\n",
    "\n",
    "for i in range(len(ls_vanilla)):\n",
    "    ls_file.write(\"%f\\t%f\\n\" % (ls_vanilla[i], ls_dist[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.247898232331895"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_val = batch_it(128, sources_val, targets_val, ending=True)\n",
    "truths = []\n",
    "preds = []\n",
    "for params in batch_val:\n",
    "    feed_dict_test={model.dropout: 0.,\n",
    "                    model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                    model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                    model.encoder_inputs: params.sources,\n",
    "                    model.targets: params.targets}\n",
    "    \n",
    "    truths.extend(arr2stn(tgt_vocab, params.targets.T))\n",
    "    preds.extend(arr2stn(tgt_vocab, np.argmax(sess.run(model.logits_eval, feed_dict_test),2)))\n",
    "    \n",
    "_bleu_online([truths], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.81, 21.23, 21.88)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18.81, 21.23, 21.88 21.90 22.28 22.63 22.67 22.72 22.97 23.11 23.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./nmt_data/tst2013.en', 'r') as f:\n",
    "    sources_tst = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "sources_tst = np.array(sources_tst)\n",
    "\n",
    "with open('./nmt_data/tst2013.vi', 'r') as f:\n",
    "    targets_tst = [[word2idx(tgt_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "targets_tst = np.array(targets_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.830047013824252"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_val = batch_it(128, sources_tst, targets_tst, ending=True)\n",
    "truths = []\n",
    "preds = []\n",
    "for params in batch_val:\n",
    "    feed_dict_test={model.dropout: 0.,\n",
    "                    model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                    model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                    model.encoder_inputs: params.sources,\n",
    "                    model.targets: params.targets}\n",
    "    \n",
    "    truths.extend(arr2stn(tgt_vocab, params.targets.T))\n",
    "    preds.extend(arr2stn(tgt_vocab, np.argmax(sess.run(model.logits_eval, feed_dict_test),2)))\n",
    "    \n",
    "_bleu_online([truths], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f17dcd3fcc0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEQp6AXEQlx/x+MT+zN5DFo1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f181010b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f17dcdcf4a8>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17a43c2668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res[-50:])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf_r1.0_3.5]",
   "language": "python",
   "name": "conda-env-tf_r1.0_3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
