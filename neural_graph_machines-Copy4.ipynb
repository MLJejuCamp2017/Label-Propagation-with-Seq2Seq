{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "UNK_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "with open('./nmt_data/vocab.en', 'r') as f, open('./nmt_data/vocab.vi', 'r') as g:\n",
    "    src_vocab = [x[:-1] for x in f.readlines()]\n",
    "    tgt_vocab = [x[:-1] for x in g.readlines()]\n",
    "    \n",
    "def list_to_dict(vocab_list):\n",
    "    ret = {}\n",
    "    for i in range(len(vocab_list)):\n",
    "        ret[i] = vocab_list[i]\n",
    "    \n",
    "    return ret\n",
    "\n",
    "src_vocab, tgt_vocab = list_to_dict(src_vocab), list_to_dict(tgt_vocab)\n",
    "src_vocab_inv, tgt_vocab_inv = {v: k for k, v in src_vocab.items()}, {v: k for k, v in tgt_vocab.items()}\n",
    "\n",
    "\n",
    "def word2idx(vocab_inv, word):\n",
    "    try:\n",
    "        ret = vocab_inv[word]\n",
    "    except:\n",
    "        ret = UNK_token\n",
    "    return ret\n",
    "\n",
    "def idx2word(vocab, idx):\n",
    "    return vocab[idx]\n",
    "\n",
    "with open('./nmt_data/train.en', 'r') as f:\n",
    "    ss_L = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "    \n",
    "with open('./nmt_data/mono.en', 'r') as f:\n",
    "    ss_U = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "    \n",
    "l = len(ss_L) #last index of labeled samples\n",
    "u = l + len(ss_U) #last index of all samples\n",
    "\n",
    "sources = ss_L\n",
    "sources0 = np.array(ss_L)\n",
    "sources.extend(ss_U)\n",
    "sources = np.array(sources)\n",
    "\n",
    "with open('./nmt_data/train.vi', 'r') as f:\n",
    "    targets = [[word2idx(tgt_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "\n",
    "targets = np.array(targets)\n",
    "\n",
    "def label(i):\n",
    "    if 0 <= i < l:\n",
    "        return targets[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from embeddings_graph import EmbeddingsGraph\n",
    "\n",
    "batch_size = 128\n",
    "max_time = 50\n",
    "time_major = True\n",
    "\n",
    "graph = EmbeddingsGraph().graph\n",
    "\n",
    "class Dummy(object):\n",
    "    pass\n",
    "\n",
    "\n",
    "def batch_iter(batch_size, sources, targets, ending=False):\n",
    "    \"\"\"\n",
    "        Generates a batch iterator for the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    data_size = len(sources)\n",
    "\n",
    "    rand_inds = np.random.permutation(np.arange(data_size))\n",
    "\n",
    "    num_batches = int(data_size / batch_size)\n",
    "\n",
    "    if data_size % batch_size > 0:\n",
    "        num_batches = int(data_size / batch_size) + 1\n",
    "\n",
    "    batch_num = 0\n",
    "    end_flag = False\n",
    "    while True:\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = (batch_num + 1) * batch_size\n",
    "        \n",
    "        if end_index > data_size:\n",
    "            if ending:\n",
    "                end_flag = True\n",
    "            else: \n",
    "                print('rebatching...')\n",
    "                batch_num = 0\n",
    "                rand_inds = np.random.permutation(rand_inds)\n",
    "                start_index = 0\n",
    "                end_index = batch_size\n",
    "        \n",
    "        \n",
    "        srcs = sources[rand_inds[start_index:end_index]]\n",
    "        tgts = targets[rand_inds[start_index:end_index]]\n",
    "        source_sequence_lengths = np.array([np.min([len(x)+1, max_time]) for x in srcs])\n",
    "        target_sequence_lengths = np.array([np.min([len(x)+1, max_time]) for x in tgts])\n",
    "        \n",
    "        srcs = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in srcs])\n",
    "        tgts = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in tgts])\n",
    "        \n",
    "        srcs = srcs.T\n",
    "        tgts = tgts.T\n",
    "        \n",
    "        params = Dummy()\n",
    "        params.source_sequence_lengths = source_sequence_lengths\n",
    "        params.target_sequence_lengths = target_sequence_lengths\n",
    "        params.sources = srcs\n",
    "        params.targets = tgts\n",
    "        \n",
    "        yield params\n",
    "        \n",
    "        if end_flag:\n",
    "            return\n",
    "        \n",
    "        batch_num += 1\n",
    "        \n",
    "def next_batch(h_edges, start, finish):\n",
    "    \"\"\"\n",
    "    Helper function for the iterator, note that the neural graph machines,\n",
    "    due to its unique loss function, requires carefully crafted inputs\n",
    "\n",
    "    Refer to the Neural Graph Machines paper, section 3 and 3.3 for more details\n",
    "    \"\"\"\n",
    "    edges_ll = list()\n",
    "    edges_lu = list()\n",
    "    edges_uu = list()\n",
    "    weights_ll = list()\n",
    "    weights_lu = list()\n",
    "    weights_uu = list()\n",
    "    batch_edges = h_edges[start:finish]\n",
    "    batch_edges = np.asarray(batch_edges)\n",
    "\n",
    "    for i, j in batch_edges[:]:\n",
    "        if (0 <= i < l) and (0 <= j < l):\n",
    "            edges_ll.append((i, j))\n",
    "            weights_ll.append(graph.get_edge_data(i,j)['weight'])\n",
    "        elif (0 <= i < l) and (l <= j < u):\n",
    "            edges_lu.append((i, j))\n",
    "            weights_lu.append(graph.get_edge_data(i,j)['weight'])\n",
    "        else:\n",
    "            edges_uu.append((i, j))\n",
    "            weights_uu.append(graph.get_edge_data(i,j)['weight'])\n",
    "    \n",
    "    if len(edges_ll)==0 or len(edges_lu)==0 or len(edges_uu)==0:\n",
    "        print(\"No matched data. Reset the batch\")\n",
    "        np.random.shuffle(h_edges[start:])\n",
    "        return next_batch(h_edges,start,finish)\n",
    "        \n",
    "\n",
    "    u_ll = [e[0] for e in edges_ll]\n",
    "\n",
    "    # number of incident edges for nodes u\n",
    "    c_ull = [1 / len(graph.edges(n)) for n in u_ll]\n",
    "    v_ll = [e[1] for e in edges_ll]\n",
    "    c_vll = [1 / len(graph.edges(n)) for n in v_ll]\n",
    "    nodes_ll_u = sources[u_ll]\n",
    "    \n",
    "    labels_ll_u = np.empty(len(u_ll), dtype=np.object)\n",
    "    labels_ll_u[:] = [label(n) for n in u_ll]\n",
    "    \n",
    "    nodes_ll_v = sources[v_ll]\n",
    "\n",
    "    labels_ll_v = np.empty(len(v_ll), dtype=np.object)\n",
    "    labels_ll_v[:] = [label(n) for n in v_ll]\n",
    "    \n",
    "    u_lu = [e[0] for e in edges_lu]\n",
    "    c_ulu = [1 / len(graph.edges(n)) for n in u_lu]\n",
    "    nodes_lu_u = sources[u_lu]\n",
    "    nodes_lu_v = sources[[e[1] for e in edges_lu]]\n",
    "\n",
    "    labels_lu = np.empty(len(u_lu), dtype=np.object)\n",
    "    labels_lu[:] = [label(n) for n in u_lu]\n",
    "    \n",
    "    nodes_uu_u = sources[[e[0] for e in edges_uu]]\n",
    "    nodes_uu_v = sources[[e[1] for e in edges_uu]]\n",
    "    \n",
    "    len_in_u1 = [np.min([len(x)+1, max_time]) for x in nodes_ll_u]\n",
    "    len_in_v1 = [np.min([len(x)+1, max_time]) for x in nodes_ll_v]\n",
    "    len_in_u2 = [np.min([len(x)+1, max_time]) for x in nodes_lu_u]\n",
    "    len_in_v2 = [np.min([len(x)+1, max_time]) for x in nodes_lu_v]\n",
    "    len_in_u3 = [np.min([len(x)+1, max_time]) for x in nodes_uu_u]\n",
    "    len_in_v3 = [np.min([len(x)+1, max_time]) for x in nodes_uu_v]\n",
    "    len_out_u1 = [np.min([len(x)+1, max_time]) for x in labels_ll_u]\n",
    "    len_out_v1 = [np.min([len(x)+1, max_time]) for x in labels_ll_v]\n",
    "    len_out_u2 = [np.min([len(x)+1, max_time]) for x in labels_lu]\n",
    "    \n",
    "    nodes_ll_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_ll_u]).T\n",
    "    nodes_ll_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_ll_v]).T\n",
    "    nodes_lu_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_lu_u]).T\n",
    "    nodes_lu_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_lu_v]).T\n",
    "    nodes_uu_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_uu_u]).T\n",
    "    nodes_uu_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in nodes_uu_v]).T\n",
    "    labels_ll_u = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in labels_ll_u]).T\n",
    "    labels_ll_v = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in labels_ll_v]).T\n",
    "    labels_lu = np.array([x[:max_time-1] + [EOS_token] + [0]*(max_time-len(x)-1) for x in labels_lu]).T\n",
    "        \n",
    "    params = Dummy()\n",
    "    params.in_u1 = nodes_ll_u\n",
    "    params.in_v1 = nodes_ll_v\n",
    "    params.out_u1 = labels_ll_u\n",
    "    params.out_v1 = labels_ll_v\n",
    "    params.in_u3 = nodes_uu_u\n",
    "    params.in_v3 = nodes_uu_v\n",
    "    params.in_u2 = nodes_lu_u\n",
    "    params.in_v2 = nodes_lu_v\n",
    "    params.out_u2 = labels_lu\n",
    "    params.weights_ll = weights_ll\n",
    "    params.weights_lu = weights_lu\n",
    "    params.weights_uu = weights_uu\n",
    "    params.cu1 = c_ull\n",
    "    params.cv1 = c_vll\n",
    "    params.cu2 = c_ulu\n",
    "        \n",
    "    params.len_in_u1 = len_in_u1\n",
    "    params.len_in_v1 = len_in_v1\n",
    "    params.len_in_u2 = len_in_u2\n",
    "    params.len_in_v2 = len_in_v2\n",
    "    params.len_in_u3 = len_in_u3\n",
    "    params.len_in_v3 = len_in_v3\n",
    "    params.len_out_u1 = len_out_u1\n",
    "    params.len_out_v1 = len_out_v1\n",
    "    params.len_out_u2 = len_out_u2\n",
    "        \n",
    "    return params\n",
    "\n",
    "\n",
    "def batch_iter_ngm(batch_size):\n",
    "    \"\"\"\n",
    "        Generates a batch iterator for the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    data_size = len(graph.edges())\n",
    "\n",
    "    edges = np.random.permutation(graph.edges())\n",
    "\n",
    "    num_batches = int(data_size / batch_size)\n",
    "\n",
    "    if data_size % batch_size > 0:\n",
    "        num_batches = int(data_size / batch_size) + 1\n",
    "\n",
    "    batch_num = 0\n",
    "    while True:\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = (batch_num + 1) * batch_size\n",
    "        \n",
    "        if end_index > data_size:\n",
    "            print(\"rebatching...\")\n",
    "            batch_num = 0\n",
    "            edges = np.random.permutation(graph.edges())\n",
    "            start_index = 0\n",
    "            end_index = batch_size\n",
    "            \n",
    "        yield next_batch(edges,start_index,end_index)\n",
    "        batch_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # Building the models\n",
    "\n",
    "# ## The Embedding\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "embedding_size = 512\n",
    "num_units = embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def initialization():\n",
    "    model = Dummy()\n",
    "    model.encoder_inputs = tf.placeholder('int32', [max_time, None], name='encoder_inputs')\n",
    "    model.targets = tf.placeholder('int32', [max_time, None], name='target')\n",
    "    model.decoder_inputs = tf.concat([tf.fill([1, tf.shape(model.targets)[1]], SOS_token), model.targets[:-1,:]], 0)\n",
    "    \n",
    "    model.source_sequence_lengths = tf.placeholder('int32', [None], name='source_sequence_lengths')\n",
    "    model.target_sequence_lengths = tf.placeholder('int32', [None], name='target_sequence_lengths')\n",
    "    \n",
    "    model.dropout = tf.placeholder('float32', [], name='dropout')\n",
    "    model.learning_rate = tf.placeholder('float32', [], name='learning_rate')\n",
    "    model.max_gradient_norm = tf.placeholder('float32', [], name='max_gradient_norm') # often set to a value like 5 or 1\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "def embedding(model):\n",
    "    with tf.variable_scope(\"embedding\", dtype='float32') as scope:\n",
    "        # Embedding\n",
    "        embedding_encoder = tf.get_variable(\"embedding_encoder\", [src_vocab_size, embedding_size])\n",
    "        embedding_decoder = tf.get_variable(\"embedding_decoder\", [tgt_vocab_size, embedding_size])\n",
    "        # Look up embedding:\n",
    "        #   encoder_inputs: [max_time, batch_size]\n",
    "        #   encoder_emp_inp: [max_time, batch_size, embedding_size]\n",
    "        encoder_emb_inp = tf.nn.embedding_lookup(embedding_encoder, model.encoder_inputs)\n",
    "        decoder_emb_inp = tf.nn.embedding_lookup(embedding_decoder, model.decoder_inputs)\n",
    "        \n",
    "        model.embedding_encoder = embedding_encoder\n",
    "        model.embedding_decoder = embedding_decoder\n",
    "        model.encoder_emb_inp = encoder_emb_inp\n",
    "        model.decoder_emb_inp = decoder_emb_inp\n",
    "        \n",
    "    return model\n",
    "\n",
    "# ## The Encoder\n",
    "def encoder(model):\n",
    "    with tf.variable_scope(\"encoder\", dtype='float32') as scope:\n",
    "        # Build RNN cell\n",
    "        # Construct forward and backward cells\n",
    "        forward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "        forward_cell = tf.contrib.rnn.DropoutWrapper(cell=forward_cell, input_keep_prob=(1.0 - model.dropout))\n",
    "        backward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "        backward_cell = tf.contrib.rnn.DropoutWrapper(cell=backward_cell, input_keep_prob=(1.0 - model.dropout))\n",
    "\n",
    "        bi_outputs, bi_encoder_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "            forward_cell, backward_cell, model.encoder_emb_inp, dtype='float32',\n",
    "            sequence_length=model.source_sequence_lengths, time_major=True)\n",
    "        bi_encoder_outputs = tf.concat(bi_outputs, -1)\n",
    "        \n",
    "        encoder_outputs = bi_encoder_outputs\n",
    "        encoder_state = bi_encoder_state\n",
    "            \n",
    "        model.encoder_outputs = encoder_outputs\n",
    "        model.encoder_state = encoder_state\n",
    "        \n",
    "    return model\n",
    "\n",
    "# ## Decoder\n",
    "def decoder(model):\n",
    "    with tf.variable_scope(\"decoder\", dtype='float32') as scope:\n",
    "        \"\"\" Attention Mechanisms \"\"\"\n",
    "        # attention_states: [batch_size, max_time, num_units]\n",
    "        attention_states = tf.transpose(model.encoder_outputs, [1, 0, 2])\n",
    "\n",
    "        # Create an attention mechanism\n",
    "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units, attention_states, scale=True,\n",
    "            memory_sequence_length=model.source_sequence_lengths)\n",
    "\n",
    "        # Build RNN cell\n",
    "        cell_list = []\n",
    "        for i in range(2):\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell=cell, input_keep_prob=(1.0 - model.dropout))\n",
    "            cell_list.append(cell)\n",
    "        \n",
    "        decoder_cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "\n",
    "        decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism,\n",
    "            attention_layer_size=num_units, name=\"attention\")\n",
    "\n",
    "        decoder_initial_state = decoder_cell.zero_state(tf.shape(model.decoder_emb_inp)[1], 'float32').clone(cell_state=model.encoder_state)\n",
    "        \"\"\"\"\"\"\n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            model.decoder_emb_inp, model.target_sequence_lengths, time_major=True)\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, decoder_initial_state)\n",
    "        # Dynamic decoding\n",
    "        outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            output_time_major=True,\n",
    "            swap_memory=True,\n",
    "            scope=scope)\n",
    "\n",
    "        #projection\n",
    "        output_layer = layers_core.Dense(tgt_vocab_size, use_bias=False, name=\"output_projection\")\n",
    "        logits = output_layer(outputs.rnn_output)\n",
    "        \n",
    "    model.logits = logits\n",
    "    model.decoder_cell = decoder_cell\n",
    "    model.decoder_initial_state = decoder_initial_state\n",
    "    model.output_layer = output_layer\n",
    "    model.final_context_state = final_context_state\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ## Loss & Gradient computation & optimization\n",
    "\n",
    "def crossent_loss(model):\n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(tf.shape(model.decoder_emb_inp)[1])\n",
    "\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def create_model():\n",
    "    model = initialization()\n",
    "    model = embedding(model)\n",
    "    model = encoder(model)\n",
    "    model = decoder(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def distance_loss(model1, model2):\n",
    "    scores_u = tf.concat((model1.final_context_state.cell_state[0].c, model1.final_context_state.cell_state[1].c), 1)\n",
    "    scores_v = tf.concat((model2.final_context_state.cell_state[0].c, model2.final_context_state.cell_state[1].c), 1)\n",
    "    \n",
    "    p = 1.0\n",
    "    epsilon = 1e-6\n",
    "    loss = tf.pow(tf.abs(scores_u - scores_v) + epsilon, p)\n",
    "    loss = tf.pow(tf.reduce_sum(loss, 1), 1/p)\n",
    "    return loss\n",
    "\n",
    "def ngm_optimizer(ngm):\n",
    "\n",
    "    l_vanilla = crossent_loss(ngm.model0)\n",
    "    #l_vanilla = tf.reduce_mean(ngm.cu_ll * vanilla_loss(ngm.model_u1))\n",
    "    #l_vanilla += tf.reduce_mean(ngm.cv_ll * vanilla_loss(ngm.model_v1))\n",
    "    #l_vanilla += tf.reduce_mean(ngm.cu_lu * vanilla_loss(ngm.model_u2))\n",
    "\n",
    "    with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "        l_dist1 = ngm.alpha_ll * ngm.weights_ll * distance_loss(ngm.model_u1, ngm.model_v1)\n",
    "        scope.reuse_variables()\n",
    "        l_dist2 = ngm.alpha_lu * ngm.weights_lu * distance_loss(ngm.model_u2, ngm.model_v2)\n",
    "        l_dist3 = ngm.alpha_uu * ngm.weights_uu * distance_loss(ngm.model_u3, ngm.model_v3)\n",
    "    ratio = .5\n",
    "    l_dist = (tf.reduce_mean(l_dist1) + tf.reduce_mean(l_dist2) + tf.reduce_mean(l_dist3)) * ratio\n",
    "    \n",
    "    loss = l_vanilla + l_dist\n",
    "    \n",
    "    # Calculate and clip gradients\n",
    "    parameters = tf.trainable_variables()\n",
    "    gradients = tf.gradients(loss, parameters)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, ngm.model_u1.max_gradient_norm)\n",
    "\n",
    "    # Optimization\n",
    "    optimizer = tf.train.GradientDescentOptimizer(ngm.model_u1.learning_rate)\n",
    "    update_step = optimizer.apply_gradients(zip(clipped_gradients, parameters))\n",
    "    \n",
    "    ngm.l_vanilla = l_vanilla\n",
    "    ngm.l_dist = l_dist\n",
    "    ngm.loss = loss\n",
    "    ngm.update_step = update_step\n",
    "    \n",
    "    return ngm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "    ngm = Dummy()\n",
    "    ngm.model0 = create_model()\n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    ngm.model_u1 = create_model()\n",
    "    ngm.model_v1 = create_model()\n",
    "    ngm.model_u2 = create_model()\n",
    "    ngm.model_v2 = create_model()\n",
    "    ngm.model_u3 = create_model()\n",
    "    ngm.model_v3 = create_model()\n",
    "    \n",
    "    ngm.alpha_ll = tf.constant(1., dtype=np.float32, name=\"alpha_ll\")\n",
    "    ngm.alpha_lu = tf.constant(1., dtype=np.float32, name=\"alpha_lu\")\n",
    "    ngm.alpha_uu = tf.constant(.5, dtype=np.float32, name=\"alpha_uu\")\n",
    "\n",
    "    ngm.weights_ll = tf.placeholder(tf.float32, [None], name=\"weights_ll\")\n",
    "    ngm.weights_lu = tf.placeholder(tf.float32, [None], name=\"weights_lu\")\n",
    "    ngm.weights_uu = tf.placeholder(tf.float32, [None], name=\"weights_uu\")\n",
    "\n",
    "    ngm.cu_ll = tf.placeholder(tf.float32, [None], name=\"cu_ll\")\n",
    "    ngm.cv_ll = tf.placeholder(tf.float32, [None], name=\"cv_ll\")\n",
    "    ngm.cu_lu = tf.placeholder(tf.float32, [None], name=\"cu_lu\")      \n",
    "\n",
    "ngm = ngm_optimizer(ngm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ## Running training\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "ls_vanilla, ls_dist = [], []\n",
    "\n",
    "batch0 = batch_iter(batch_size, sources0, targets)\n",
    "batch = batch_iter_ngm(batch_size//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bleu import _bleu_online\n",
    "\n",
    "def arr2stn(vocab, sentences):\n",
    "    def foo_iter(stn):\n",
    "        try:\n",
    "            end_idx = stn.index(EOS_token)\n",
    "        except:\n",
    "            end_idx = len(stn)\n",
    "        return ' '.join([idx2word(vocab, word) for word in stn[:end_idx]])\n",
    "    \n",
    "    sentences = sentences.tolist()\n",
    "    ret = []\n",
    "    \n",
    "    if len(sentences)==0:\n",
    "        stn = sentences\n",
    "        ret.append(foo_iter(stn))\n",
    "        \n",
    "    else:\n",
    "        for stn in sentences:\n",
    "            ret.append(foo_iter(stn))\n",
    "    return ret\n",
    "\n",
    "# # Evaluating the network\n",
    "def evaluation(model):\n",
    "    # In[34]:\n",
    "\n",
    "    model.maximum_iterations = tf.round(tf.reduce_max(model.source_sequence_lengths) * 2)\n",
    "\n",
    "\n",
    "    # In[35]:\n",
    "\n",
    "    with tf.variable_scope('decoder', reuse=True) as scope:\n",
    "    # Dynamic decoding\n",
    "        # Helper\n",
    "        helper_eval = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            model.embedding_decoder, tf.fill([tf.shape(model.decoder_emb_inp)[1]], SOS_token),\n",
    "            EOS_token)\n",
    "        # Decoder\n",
    "        decoder_eval = tf.contrib.seq2seq.BasicDecoder(\n",
    "            model.decoder_cell, helper_eval, model.decoder_initial_state,\n",
    "            output_layer=model.output_layer)\n",
    "\n",
    "        outputs_eval, final_context_state_eval, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder_eval, maximum_iterations=model.maximum_iterations,\n",
    "            swap_memory=True, scope=scope)\n",
    "\n",
    "        model.logits_eval = outputs_eval.rnn_output\n",
    "        \n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(tf.shape(model.decoder_emb_inp)[1])\n",
    "    \n",
    "    model.loss_eval = loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = evaluation(ngm.model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./nmt_data/tst2012.en', 'r') as f:\n",
    "    sources_val = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "sources_val = np.array(sources_val)\n",
    "\n",
    "with open('./nmt_data/tst2012.vi', 'r') as f:\n",
    "    targets_val = [[word2idx(tgt_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "targets_val = np.array(targets_val)\n",
    "\n",
    "res = []\n",
    "\n",
    "with open('./nmt_data/tst2013.en', 'r') as f:\n",
    "    sources_tst = [[word2idx(src_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "sources_tst = np.array(sources_tst)\n",
    "\n",
    "with open('./nmt_data/tst2013.vi', 'r') as f:\n",
    "    targets_tst = [[word2idx(tgt_vocab_inv, word)for word in sentence[:-1].split(' ')] for sentence in f.readlines()]\n",
    "targets_tst = np.array(targets_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 0) 194.806 7.29709\n",
      "198.345\n",
      "('1', 100) 215.161 51.6844\n",
      "186.314\n",
      "('1', 200) 162.132 13.0585\n",
      "148.87\n",
      "No matched data. Reset the batch\n",
      "('1', 300) 177.614 6.46966\n",
      "152.829\n",
      "('1', 326) 169.465 3.74377\r"
     ]
    }
   ],
   "source": [
    "t_str = time()\n",
    "#display.clear_output(wait=False)\n",
    "#f, axarr = plt.subplots(1, 2, figsize=(20,10))\n",
    "for i in range(0, 18000):\n",
    "    params = next(batch)\n",
    "    params0 = next(batch0)\n",
    "    \n",
    "    if i == 0:\n",
    "        learning_rate = 1.\n",
    "        phase = '1'\n",
    "    elif i == 12000:\n",
    "        #saver.restore(sess, './log/ngm_256_l1_%s.ckpt' % phase)\n",
    "        learning_rate = .5\n",
    "        phase = '2'\n",
    "    elif i == 13500:\n",
    "        #saver.restore(sess, './log/ngm_256_l1_%s.ckpt' % phase)\n",
    "        learning_rate = .25\n",
    "        phase = '3'\n",
    "    elif i == 15000:\n",
    "        #saver.restore(sess, './log/ngm_256_l1_%s.ckpt' % phase)\n",
    "        learning_rate = .125\n",
    "        phase = '4'\n",
    "    elif i == 16500:\n",
    "        #saver.restore(sess, './log/ngm_256_l1_%s.ckpt' % phase)\n",
    "        learning_rate = .0625\n",
    "        phase = '5'\n",
    "        \n",
    "    feed_dict={ngm.model0.dropout: .2,\n",
    "               ngm.model0.source_sequence_lengths: params0.source_sequence_lengths,\n",
    "               ngm.model0.target_sequence_lengths: params0.target_sequence_lengths,\n",
    "               ngm.model0.encoder_inputs: params0.sources,\n",
    "               ngm.model0.targets: params0.targets,\n",
    "               \n",
    "               ngm.model_u1.learning_rate: learning_rate,\n",
    "               ngm.model_u1.max_gradient_norm: 5,\n",
    "               ngm.weights_ll: params.weights_ll,\n",
    "               ngm.weights_lu: params.weights_lu,\n",
    "               ngm.weights_uu: params.weights_uu,\n",
    "               ngm.cu_ll: params.cu1,\n",
    "               ngm.cv_ll: params.cv1,\n",
    "               ngm.cu_lu: params.cu2,\n",
    "               \n",
    "               ngm.model_u1.dropout: .2,\n",
    "               ngm.model_v1.dropout: .2,\n",
    "               ngm.model_u2.dropout: .2,\n",
    "               ngm.model_v2.dropout: .2,\n",
    "               ngm.model_u3.dropout: .2,\n",
    "               ngm.model_v3.dropout: .2,\n",
    "               \n",
    "               ngm.model_u1.source_sequence_lengths: params.len_in_u1,\n",
    "               ngm.model_u1.target_sequence_lengths: params.len_out_u1,\n",
    "               ngm.model_u1.encoder_inputs: params.in_u1,\n",
    "               ngm.model_u1.targets: params.out_u1,\n",
    "               \n",
    "               ngm.model_v1.source_sequence_lengths: params.len_in_v1,\n",
    "               ngm.model_v1.target_sequence_lengths: params.len_out_v1,\n",
    "               ngm.model_v1.encoder_inputs: params.in_v1,\n",
    "               ngm.model_v1.targets: params.out_v1,\n",
    "               \n",
    "               ngm.model_u2.source_sequence_lengths: params.len_in_u2,\n",
    "               ngm.model_u2.target_sequence_lengths: params.len_out_u2,\n",
    "               ngm.model_u2.encoder_inputs: params.in_u2,\n",
    "               ngm.model_u2.targets: params.out_u2,\n",
    "               \n",
    "               ngm.model_v2.source_sequence_lengths: params.len_in_v2,\n",
    "               ngm.model_v2.target_sequence_lengths: np.ones(params.in_v2.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v2.encoder_inputs: params.in_v2,\n",
    "               ngm.model_v2.targets: np.ones((max_time, params.in_v2.shape[1]), 'int32') * EOS_token,\n",
    "\n",
    "               ngm.model_u3.source_sequence_lengths: params.len_in_u3,\n",
    "               ngm.model_u3.target_sequence_lengths: np.ones(params.in_u3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_u3.encoder_inputs: params.in_u3,\n",
    "               ngm.model_u3.targets: np.ones((max_time, params.in_u3.shape[1]), 'int32') * EOS_token,\n",
    "               \n",
    "               ngm.model_v3.source_sequence_lengths: params.len_in_v3,\n",
    "               ngm.model_v3.target_sequence_lengths: np.ones(params.in_v3.shape[1], 'float32') * EOS_token,\n",
    "               ngm.model_v3.encoder_inputs: params.in_v3,\n",
    "               ngm.model_v3.targets: np.ones((max_time, params.in_v3.shape[1]), 'int32') * EOS_token\n",
    "               }\n",
    "\n",
    "\n",
    "    _, l_v, l_d = sess.run([ngm.update_step, ngm.l_vanilla, ngm.l_dist], feed_dict=feed_dict)\n",
    "    ls_vanilla.append(l_v)\n",
    "    ls_dist.append(l_d)\n",
    "    print((phase, i), l_v, l_d, end='\\r')\n",
    "    \n",
    "    if (i % 100 == 0):\n",
    "        batch_val = batch_iter(128, sources_val, targets_val, ending=True)\n",
    "        tmp_vals = []\n",
    "        for params in batch_val:\n",
    "            feed_dict_test={model.dropout: 0.,\n",
    "                            model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                            model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                            model.encoder_inputs: params.sources,\n",
    "                            model.targets: params.targets}\n",
    "            tmp_vals.append(sess.run(model.loss_eval, feed_dict_test))\n",
    "        res.append(np.mean(tmp_vals))\n",
    "        if res[-1] == np.min(res):\n",
    "            saver.save(sess, './log/ngm_512_l1_%s.ckpt' % phase)\n",
    "        print()\n",
    "        print(res[-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff8e408d0f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9701091d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ls_dist[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e10ea0860>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQW6iIhPKNBFRHxCgS4i4hP/H1RPKvGCNkHaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6da5859898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ls_dist[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "saver.save(sess, './log/ngm_512_l1_final_half.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ls_file = open('./ngm_512_l1_half_ls.txt', 'w')\n",
    "\n",
    "for i in range(len(ls_vanilla)):\n",
    "    ls_file.write(\"%f\\t%f\\n\" % (ls_vanilla[i], ls_dist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.18, 27.46)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24.18, 27.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.56, 27.45)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24.56, 27.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.55967592801542"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_val = batch_iter(128, sources_val, targets_val, ending=True)\n",
    "truths = []\n",
    "preds = []\n",
    "for params in batch_val:\n",
    "    feed_dict_test={model.dropout: 0.,\n",
    "                    model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                    model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                    model.encoder_inputs: params.sources,\n",
    "                    model.targets: params.targets}\n",
    "    \n",
    "    truths.extend(arr2stn(tgt_vocab, params.targets.T))\n",
    "    preds.extend(arr2stn(tgt_vocab, np.argmax(sess.run(model.logits_eval, feed_dict_test),2)))\n",
    "    \n",
    "_bleu_online([truths], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.45680880982154"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_val = batch_iter(128, sources_tst, targets_tst, ending=True)\n",
    "truths = []\n",
    "preds = []\n",
    "for params in batch_val:\n",
    "    feed_dict_test={model.dropout: 0.,\n",
    "                    model.source_sequence_lengths: params.source_sequence_lengths,\n",
    "                    model.target_sequence_lengths: params.target_sequence_lengths,\n",
    "                    model.encoder_inputs: params.sources,\n",
    "                    model.targets: params.targets}\n",
    "    \n",
    "    truths.extend(arr2stn(tgt_vocab, params.targets.T))\n",
    "    preds.extend(arr2stn(tgt_vocab, np.argmax(sess.run(model.logits_eval, feed_dict_test),2)))\n",
    "    \n",
    "_bleu_online([truths], preds)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf_r1.0_3.5]",
   "language": "python",
   "name": "conda-env-tf_r1.0_3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
