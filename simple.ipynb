{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Dense, merge\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "# plot part.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(2)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LSTM in module keras.layers.recurrent:\n",
      "\n",
      "class LSTM(Recurrent)\n",
      " |  Long-Short Term Memory unit - Hochreiter 1997.\n",
      " |  \n",
      " |  For a step-by-step description of the algorithm, see\n",
      " |  [this tutorial](http://deeplearning.net/tutorial/lstm.html).\n",
      " |  \n",
      " |  # Arguments\n",
      " |      units: Positive integer, dimensionality of the output space.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you pass None, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      recurrent_activation: Activation function to use\n",
      " |          for the recurrent step\n",
      " |          (see [activations](../activations.md)).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix,\n",
      " |          used for the linear transformation of the inputs.\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      recurrent_initializer: Initializer for the `recurrent_kernel`\n",
      " |          weights matrix,\n",
      " |          used for the linear transformation of the recurrent state.\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      unit_forget_bias: Boolean.\n",
      " |          If True, add 1 to the bias of the forget gate at initialization.\n",
      " |          Setting it to true will also force `bias_initializer=\"zeros\"`.\n",
      " |          This is recommended in [Jozefowicz et al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      recurrent_regularizer: Regularizer function applied to\n",
      " |          the `recurrent_kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      recurrent_constraint: Constraint function applied to\n",
      " |          the `recurrent_kernel` weights matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      dropout: Float between 0 and 1.\n",
      " |          Fraction of the units to drop for\n",
      " |          the linear transformation of the inputs.\n",
      " |      recurrent_dropout: Float between 0 and 1.\n",
      " |          Fraction of the units to drop for\n",
      " |          the linear transformation of the recurrent state.\n",
      " |  \n",
      " |  # References\n",
      " |      - [Long short-term memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) (original 1997 paper)\n",
      " |      - [Learning to forget: Continual prediction with LSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n",
      " |      - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n",
      " |      - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LSTM\n",
      " |      Recurrent\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_constants(self, inputs, training=None)\n",
      " |  \n",
      " |  preprocess_input(self, inputs, training=None)\n",
      " |  \n",
      " |  step(self, inputs, states)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Recurrent:\n",
      " |  \n",
      " |  __call__(self, inputs, initial_state=None, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  call(self, inputs, mask=None, training=None, initial_state=None)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_initial_state(self, inputs)\n",
      " |  \n",
      " |  reset_states(self, states=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  constraints\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_3/transpose_1:0' shape=(?, ?, 32) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32))\n",
    "model.add()\n",
    "def encoder(x):\n",
    "    lstm_units = 32\n",
    "    lstm_out = LSTM(lstm_units)(x)\n",
    "    \n",
    "    return lstm_out\n",
    "\n",
    "def attention(x):\n",
    "    attention_probs = Dense(x.shape[1:], activation='softmax', name='attention_vec')(x)\n",
    "    attention_mul = merge([x, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "    return attention_mul\n",
    "\n",
    "def decoder(x):\n",
    "    lstm_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "    # Documentation is available online on Github at the address below.\n",
    "    # From: https://github.com/philipperemy/keras-visualize-activations\n",
    "    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "    funcs = [K.function([inp] + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def get_data(n, input_dim, attention_column=1):\n",
    "    \"\"\"\n",
    "    Data generation. x is purely random except that it's first value equals the target y.\n",
    "    In practice, the network should learn that the target = x[attention_column].\n",
    "    Therefore, most of its attention should be focused on the value addressed by attention_column.\n",
    "    :param n: the number of samples to retrieve.\n",
    "    :param input_dim: the number of dimensions of each element in the series.\n",
    "    :param attention_column: the column linked to the target. Everything else is purely random.\n",
    "    :return: x: model inputs, y: model targets\n",
    "    \"\"\"\n",
    "    x = np.random.standard_normal(size=(n, input_dim))\n",
    "    y = np.random.randint(low=0, high=2, size=(n, 1))\n",
    "    x[:, attention_column] = y[:, 0]\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/jay/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/jay/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 32)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec (Dense)            (None, 32)            1056        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul (Merge)            (None, 32)            0           input_1[0][0]                    \n",
      "                                                                   attention_vec[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 64)            2112        attention_mul[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             65          dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,233\n",
      "Trainable params: 3,233\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "5000/5000 [==============================] - 12s - loss: 0.6821 - acc: 0.6232 - val_loss: 0.6697 - val_acc: 0.6956\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.6380 - acc: 0.7472 - val_loss: 0.6007 - val_acc: 0.7832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.5419 - acc: 0.7990 - val_loss: 0.4933 - val_acc: 0.8154\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.4285 - acc: 0.8406 - val_loss: 0.3849 - val_acc: 0.8654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.3147 - acc: 0.8904 - val_loss: 0.2712 - val_acc: 0.9026\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.1990 - acc: 0.9472 - val_loss: 0.1570 - val_acc: 0.9596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0990 - acc: 0.9846 - val_loss: 0.0699 - val_acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0395 - acc: 0.9980 - val_loss: 0.0282 - val_acc: 0.9984\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0156 - acc: 0.9998 - val_loss: 0.0129 - val_acc: 0.9994\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/20\n",
      "5000/5000 [==============================] - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/20\n",
      "5000/5000 [==============================] - 0s - loss: 9.9870e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/20\n",
      "5000/5000 [==============================] - 0s - loss: 8.3156e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/20\n",
      "5000/5000 [==============================] - 0s - loss: 7.0476e-04 - acc: 1.0000 - val_loss: 8.6610e-04 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/20\n",
      "5000/5000 [==============================] - 0s - loss: 6.0527e-04 - acc: 1.0000 - val_loss: 7.4690e-04 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/20\n",
      "5000/5000 [==============================] - 0s - loss: 5.2512e-04 - acc: 1.0000 - val_loss: 6.4993e-04 - val_acc: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "----- activations -----\n",
      "(1, 32)\n",
      "attention = [ 0.01150439  0.52673459  0.00755711  0.01150719  0.02424358  0.01212192\n",
      "  0.04357561  0.00705418  0.02108058  0.01616957  0.00857382  0.01049989\n",
      "  0.00967148  0.01578269  0.02054159  0.01533546  0.00677061  0.01053954\n",
      "  0.01014397  0.00950988  0.01210484  0.04223045  0.01706539  0.00788361\n",
      "  0.00999341  0.01664016  0.01594767  0.01538591  0.00839068  0.02028575\n",
      "  0.02437523  0.01077924]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAELCAYAAAAiIMZEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f9a40f6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim = 32\n",
    "\n",
    "def build_model():\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # ATTENTION PART STARTS HERE\n",
    "    attention_probs = Dense(input_dim, activation='softmax', name='attention_vec')(inputs)\n",
    "    attention_mul = merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "    # ATTENTION PART FINISHES HERE\n",
    "\n",
    "    attention_mul = Dense(64)(attention_mul)\n",
    "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "    model = Model(input=[inputs], output=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    N = 10000\n",
    "    inputs_1, outputs = get_data(N, input_dim)\n",
    "\n",
    "    m = build_model()\n",
    "    m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(m.summary())\n",
    "\n",
    "    m.fit([inputs_1], outputs, epochs=20, batch_size=64, validation_split=0.5)\n",
    "\n",
    "    testing_inputs_1, testing_outputs = get_data(1, input_dim)\n",
    "\n",
    "    # Attention vector corresponds to the second matrix.\n",
    "    # The first one is the Inputs output.\n",
    "    attention_vector = get_activations(m, testing_inputs_1,\n",
    "                                       print_shape_only=True,\n",
    "                                       layer_name='attention_vec')[0].flatten()\n",
    "    print('attention =', attention_vector)\n",
    "\n",
    "    # plot part.\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    pd.DataFrame(attention_vector, columns=['attention (%)']).plot(kind='bar',\n",
    "                                                                   title='Attention Mechanism as '\n",
    "                                                                         'a function of input'\n",
    "                                                                         ' dimensions.')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
